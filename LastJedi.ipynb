{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501470\n",
      "Length of vocabulary =  93\n"
     ]
    }
   ],
   "source": [
    "data_str = (open(r\"../data/input.txt\")).read()\n",
    "print(len(data_str))\n",
    "data = [i for i in data_str]\n",
    "data_set = sorted(set(data_str))\n",
    "print(\"Length of vocabulary = \", len(data_set))\n",
    "char_2_idx = {ch: i for i, ch in enumerate(data_set)}\n",
    "idx_2_char = {i: ch for i, ch in enumerate(data_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.array([char_2_idx[i] for i in data_str])\n",
    "train_data = data[0:int(0.8 * len(data))]\n",
    "y_train = data[1:int(0.8 * len(data)) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401176,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = to_categorical(train_data, len(data_set))\n",
    "val_data = data[int(0.8 * len(data)):-1]\n",
    "y_val = data[int(0.8 * len(data)) + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 80, 67, ..., 67, 76, 66])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "length_to_keep = int(len(train_data) / batch_size) * len(data_set)*batch_size\n",
    "train_data = train_data[0:int(length_to_keep / len(data_set)), :].copy()\n",
    "train_data = np.reshape(train_data, (int(len(train_data) / batch_size), batch_size, len(data_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16047, 25, 93)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_data[:, :-1, :]\n",
    "y = train_data[:, 1:, :]\n",
    "X_val = to_categorical(val_data, len(data_set))\n",
    "length_to_keep = int(len(X_val) / batch_size) * len(data_set)* batch_size\n",
    "X_val = X_val[0:int(length_to_keep / len(data_set)), :].copy()\n",
    "X_val = np.reshape(X_val, (int(len(X_val) / batch_size), batch_size, len(data_set)))\n",
    "y_val = X_val[:, 1:, :]\n",
    "X_val = X_val[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'D:\\\\Resource\\\\Courses\\\\UCSD\\\\2nd_Quarter\\\\253\\\\pa4\\\\DeepMusic\\\\utils.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr, ytr, xva, yva = utils.get_dateset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4011, 24, 93)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yva.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       ..., \n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]], dtype=bool)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val==yva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16047, 24, 93)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = enc.fit_transform(np.reshape(train_data, (-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = enc.transform(np.reshape(train_data, (-1,1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_k == t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What if I tried on Keras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, SimpleRNN, LSTM\n",
    "from keras.callbacks import History\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               77600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 93)                9393      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 93)                0         \n",
      "=================================================================\n",
      "Total params: 86,993\n",
      "Trainable params: 86,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SOFTWARE\\Conda\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16047 samples, validate on 4011 samples\n",
      "Epoch 1/100\n",
      "16047/16047 [==============================] - 20s 1ms/step - loss: 3.7263 - acc: 0.1335 - val_loss: 3.4945 - val_acc: 0.1274\n",
      "Epoch 2/100\n",
      "16047/16047 [==============================] - 14s 893us/step - loss: 3.3702 - acc: 0.1474 - val_loss: 3.2814 - val_acc: 0.1391\n",
      "Epoch 3/100\n",
      "16047/16047 [==============================] - 17s 1ms/step - loss: 3.2068 - acc: 0.1689 - val_loss: 3.1275 - val_acc: 0.1608\n",
      "Epoch 4/100\n",
      "16047/16047 [==============================] - 16s 968us/step - loss: 3.0575 - acc: 0.2003 - val_loss: 2.9718 - val_acc: 0.1852\n",
      "Epoch 5/100\n",
      "16047/16047 [==============================] - 16s 981us/step - loss: 2.9076 - acc: 0.2259 - val_loss: 2.8726 - val_acc: 0.1985\n",
      "Epoch 6/100\n",
      "16047/16047 [==============================] - 16s 972us/step - loss: 2.7802 - acc: 0.2541 - val_loss: 2.7680 - val_acc: 0.2319\n",
      "Epoch 7/100\n",
      "16047/16047 [==============================] - 16s 976us/step - loss: 2.6687 - acc: 0.2813 - val_loss: 2.7038 - val_acc: 0.2508\n",
      "Epoch 8/100\n",
      "16047/16047 [==============================] - 16s 998us/step - loss: 2.5635 - acc: 0.3097 - val_loss: 2.6273 - val_acc: 0.2625\n",
      "Epoch 9/100\n",
      "16047/16047 [==============================] - 15s 932us/step - loss: 2.4667 - acc: 0.3384 - val_loss: 2.5420 - val_acc: 0.2907\n",
      "Epoch 10/100\n",
      "16047/16047 [==============================] - 15s 945us/step - loss: 2.3783 - acc: 0.3599 - val_loss: 2.5130 - val_acc: 0.2914\n",
      "Epoch 11/100\n",
      "16047/16047 [==============================] - 15s 940us/step - loss: 2.3013 - acc: 0.3778 - val_loss: 2.4525 - val_acc: 0.3106\n",
      "Epoch 12/100\n",
      "16047/16047 [==============================] - 15s 961us/step - loss: 2.2369 - acc: 0.3943 - val_loss: 2.4092 - val_acc: 0.3234\n",
      "Epoch 13/100\n",
      "16047/16047 [==============================] - 16s 1ms/step - loss: 2.1697 - acc: 0.4120 - val_loss: 2.3635 - val_acc: 0.3348\n",
      "Epoch 14/100\n",
      "16047/16047 [==============================] - 16s 989us/step - loss: 2.1114 - acc: 0.4249 - val_loss: 2.3455 - val_acc: 0.3363\n",
      "Epoch 15/100\n",
      "16047/16047 [==============================] - 16s 1ms/step - loss: 2.0552 - acc: 0.4408 - val_loss: 2.3508 - val_acc: 0.3351\n",
      "Epoch 16/100\n",
      "16047/16047 [==============================] - 16s 998us/step - loss: 2.0052 - acc: 0.4543 - val_loss: 2.2932 - val_acc: 0.3453\n",
      "Epoch 17/100\n",
      "16047/16047 [==============================] - 17s 1ms/step - loss: 1.9599 - acc: 0.4618 - val_loss: 2.2883 - val_acc: 0.3451\n",
      "Epoch 18/100\n",
      "16047/16047 [==============================] - 16s 990us/step - loss: 1.9143 - acc: 0.4742 - val_loss: 2.2775 - val_acc: 0.3518\n",
      "Epoch 19/100\n",
      "16047/16047 [==============================] - 15s 950us/step - loss: 1.8683 - acc: 0.4843 - val_loss: 2.2582 - val_acc: 0.3563\n",
      "Epoch 20/100\n",
      "16047/16047 [==============================] - 15s 950us/step - loss: 1.8304 - acc: 0.4942 - val_loss: 2.2481 - val_acc: 0.3563\n",
      "Epoch 21/100\n",
      "16047/16047 [==============================] - 15s 941us/step - loss: 1.7921 - acc: 0.5002 - val_loss: 2.2523 - val_acc: 0.3625\n",
      "Epoch 22/100\n",
      "16047/16047 [==============================] - 15s 945us/step - loss: 1.7541 - acc: 0.5090 - val_loss: 2.2155 - val_acc: 0.3682\n",
      "Epoch 23/100\n",
      "16047/16047 [==============================] - 15s 945us/step - loss: 1.7156 - acc: 0.5175 - val_loss: 2.2190 - val_acc: 0.3647\n",
      "Epoch 24/100\n",
      "16047/16047 [==============================] - 15s 944us/step - loss: 1.6850 - acc: 0.5238 - val_loss: 2.2167 - val_acc: 0.3715\n",
      "Epoch 25/100\n",
      "16047/16047 [==============================] - 15s 944us/step - loss: 1.6474 - acc: 0.5336 - val_loss: 2.2141 - val_acc: 0.3645\n",
      "Epoch 26/100\n",
      "16047/16047 [==============================] - 15s 945us/step - loss: 1.6143 - acc: 0.5423 - val_loss: 2.1958 - val_acc: 0.3760\n",
      "Epoch 27/100\n",
      "16047/16047 [==============================] - 15s 940us/step - loss: 1.5852 - acc: 0.5484 - val_loss: 2.2162 - val_acc: 0.3677\n",
      "Epoch 28/100\n",
      "16047/16047 [==============================] - 15s 946us/step - loss: 1.5501 - acc: 0.5584 - val_loss: 2.2139 - val_acc: 0.3727\n",
      "Epoch 29/100\n",
      "16047/16047 [==============================] - 15s 931us/step - loss: 1.5204 - acc: 0.5669 - val_loss: 2.1898 - val_acc: 0.3805\n",
      "Epoch 30/100\n",
      "16047/16047 [==============================] - 15s 932us/step - loss: 1.4839 - acc: 0.5741 - val_loss: 2.1958 - val_acc: 0.3675\n",
      "Epoch 31/100\n",
      "16047/16047 [==============================] - 15s 935us/step - loss: 1.4544 - acc: 0.5851 - val_loss: 2.2188 - val_acc: 0.3680\n",
      "Epoch 32/100\n",
      "16047/16047 [==============================] - 15s 933us/step - loss: 1.4249 - acc: 0.5841 - val_loss: 2.2124 - val_acc: 0.3692\n",
      "Epoch 33/100\n",
      "16047/16047 [==============================] - 15s 932us/step - loss: 1.3994 - acc: 0.5944 - val_loss: 2.2636 - val_acc: 0.3700\n",
      "Epoch 34/100\n",
      "16047/16047 [==============================] - 15s 933us/step - loss: 1.3712 - acc: 0.6004 - val_loss: 2.2152 - val_acc: 0.3710\n",
      "Epoch 35/100\n",
      "16047/16047 [==============================] - 15s 931us/step - loss: 1.3404 - acc: 0.6084 - val_loss: 2.2432 - val_acc: 0.3650\n",
      "Epoch 36/100\n",
      "16047/16047 [==============================] - 15s 928us/step - loss: 1.3117 - acc: 0.6187 - val_loss: 2.2474 - val_acc: 0.3772\n",
      "Epoch 37/100\n",
      "16047/16047 [==============================] - 15s 931us/step - loss: 1.2855 - acc: 0.6257 - val_loss: 2.2728 - val_acc: 0.3655\n",
      "Epoch 38/100\n",
      "16047/16047 [==============================] - 15s 932us/step - loss: 1.2588 - acc: 0.6353 - val_loss: 2.2771 - val_acc: 0.3652\n",
      "Epoch 39/100\n",
      "16047/16047 [==============================] - 15s 932us/step - loss: 1.2317 - acc: 0.6381 - val_loss: 2.2887 - val_acc: 0.3747\n",
      "Epoch 40/100\n",
      "16047/16047 [==============================] - 15s 934us/step - loss: 1.2040 - acc: 0.6495 - val_loss: 2.2866 - val_acc: 0.3697\n",
      "Epoch 41/100\n",
      "16047/16047 [==============================] - 15s 933us/step - loss: 1.1733 - acc: 0.6578 - val_loss: 2.3448 - val_acc: 0.3628\n",
      "Epoch 42/100\n",
      "16047/16047 [==============================] - 15s 930us/step - loss: 1.1518 - acc: 0.6636 - val_loss: 2.3483 - val_acc: 0.3685\n",
      "Epoch 43/100\n",
      "16047/16047 [==============================] - 15s 928us/step - loss: 1.1290 - acc: 0.6682 - val_loss: 2.3848 - val_acc: 0.3642\n",
      "Epoch 44/100\n",
      "16047/16047 [==============================] - 15s 930us/step - loss: 1.1117 - acc: 0.6758 - val_loss: 2.4002 - val_acc: 0.3652\n",
      "Epoch 45/100\n",
      "16047/16047 [==============================] - 15s 934us/step - loss: 1.0801 - acc: 0.6852 - val_loss: 2.4503 - val_acc: 0.3590\n",
      "Epoch 46/100\n",
      "16047/16047 [==============================] - 15s 932us/step - loss: 1.0549 - acc: 0.6903 - val_loss: 2.4546 - val_acc: 0.3573\n",
      "Epoch 47/100\n",
      "16047/16047 [==============================] - 15s 925us/step - loss: 1.0283 - acc: 0.7002 - val_loss: 2.4366 - val_acc: 0.3580\n",
      "Epoch 48/100\n",
      "16047/16047 [==============================] - 15s 933us/step - loss: 1.0023 - acc: 0.7090 - val_loss: 2.5017 - val_acc: 0.3503\n",
      "Epoch 49/100\n",
      "16047/16047 [==============================] - 15s 933us/step - loss: 0.9859 - acc: 0.7151 - val_loss: 2.5112 - val_acc: 0.3528\n",
      "Epoch 50/100\n",
      "16047/16047 [==============================] - 15s 940us/step - loss: 0.9645 - acc: 0.7194 - val_loss: 2.5329 - val_acc: 0.3570\n",
      "Epoch 51/100\n",
      "16047/16047 [==============================] - 16s 1000us/step - loss: 0.9380 - acc: 0.7268 - val_loss: 2.5270 - val_acc: 0.3563\n",
      "Epoch 52/100\n",
      "16047/16047 [==============================] - 15s 957us/step - loss: 0.9208 - acc: 0.7330 - val_loss: 2.5308 - val_acc: 0.3593\n",
      "Epoch 53/100\n",
      "16047/16047 [==============================] - 15s 946us/step - loss: 0.8907 - acc: 0.7423 - val_loss: 2.6024 - val_acc: 0.3473\n",
      "Epoch 54/100\n",
      "16047/16047 [==============================] - 15s 943us/step - loss: 0.8708 - acc: 0.7490 - val_loss: 2.6514 - val_acc: 0.3533\n",
      "Epoch 55/100\n",
      "16047/16047 [==============================] - 15s 949us/step - loss: 0.8546 - acc: 0.7540 - val_loss: 2.6377 - val_acc: 0.3498\n",
      "Epoch 56/100\n",
      "16047/16047 [==============================] - 15s 952us/step - loss: 0.8288 - acc: 0.7633 - val_loss: 2.6576 - val_acc: 0.3453\n",
      "Epoch 57/100\n",
      "16047/16047 [==============================] - 15s 947us/step - loss: 0.8092 - acc: 0.7713 - val_loss: 2.6952 - val_acc: 0.3408\n",
      "Epoch 58/100\n",
      "16047/16047 [==============================] - 15s 942us/step - loss: 0.7876 - acc: 0.7763 - val_loss: 2.7181 - val_acc: 0.3488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "16047/16047 [==============================] - 15s 953us/step - loss: 0.7692 - acc: 0.7777 - val_loss: 2.7651 - val_acc: 0.3403\n",
      "Epoch 60/100\n",
      "16047/16047 [==============================] - 16s 987us/step - loss: 0.7533 - acc: 0.7868 - val_loss: 2.7724 - val_acc: 0.3458\n",
      "Epoch 61/100\n",
      "16047/16047 [==============================] - 15s 952us/step - loss: 0.7377 - acc: 0.7896 - val_loss: 2.7881 - val_acc: 0.3473\n",
      "Epoch 62/100\n",
      "16047/16047 [==============================] - 15s 938us/step - loss: 0.7157 - acc: 0.7967 - val_loss: 2.8758 - val_acc: 0.3411\n",
      "Epoch 63/100\n",
      "16047/16047 [==============================] - 15s 940us/step - loss: 0.6909 - acc: 0.8075 - val_loss: 2.8479 - val_acc: 0.3413\n",
      "Epoch 64/100\n",
      "16047/16047 [==============================] - 15s 935us/step - loss: 0.6754 - acc: 0.8108 - val_loss: 2.9086 - val_acc: 0.3416\n",
      "Epoch 65/100\n",
      "16047/16047 [==============================] - 15s 936us/step - loss: 0.6564 - acc: 0.8162 - val_loss: 2.9205 - val_acc: 0.3366\n",
      "Epoch 66/100\n",
      "16047/16047 [==============================] - 15s 938us/step - loss: 0.6414 - acc: 0.8200 - val_loss: 2.9381 - val_acc: 0.3396\n",
      "Epoch 67/100\n",
      "16047/16047 [==============================] - 15s 934us/step - loss: 0.6208 - acc: 0.8269 - val_loss: 2.9882 - val_acc: 0.3353\n",
      "Epoch 68/100\n",
      "16047/16047 [==============================] - 15s 932us/step - loss: 0.6071 - acc: 0.8319 - val_loss: 3.0207 - val_acc: 0.3353\n",
      "Epoch 69/100\n",
      "16047/16047 [==============================] - 15s 929us/step - loss: 0.5949 - acc: 0.8347 - val_loss: 3.0405 - val_acc: 0.3436\n",
      "Epoch 70/100\n",
      "16047/16047 [==============================] - 15s 931us/step - loss: 0.5775 - acc: 0.8426 - val_loss: 3.0202 - val_acc: 0.3356\n",
      "Epoch 71/100\n",
      "16047/16047 [==============================] - 15s 928us/step - loss: 0.5604 - acc: 0.8461 - val_loss: 3.0422 - val_acc: 0.3401\n",
      "Epoch 72/100\n",
      "16047/16047 [==============================] - 15s 928us/step - loss: 0.5426 - acc: 0.8521 - val_loss: 3.1310 - val_acc: 0.3363\n",
      "Epoch 73/100\n",
      "16047/16047 [==============================] - 15s 928us/step - loss: 0.5417 - acc: 0.8536 - val_loss: 3.1651 - val_acc: 0.3269\n",
      "Epoch 74/100\n",
      "16047/16047 [==============================] - 15s 964us/step - loss: 0.5155 - acc: 0.8615 - val_loss: 3.1605 - val_acc: 0.3356\n",
      "Epoch 75/100\n",
      "16047/16047 [==============================] - 15s 945us/step - loss: 0.4996 - acc: 0.8671 - val_loss: 3.1769 - val_acc: 0.3396\n",
      "Epoch 76/100\n",
      "16047/16047 [==============================] - 15s 946us/step - loss: 0.4825 - acc: 0.8724 - val_loss: 3.2108 - val_acc: 0.3301\n",
      "Epoch 77/100\n",
      "16047/16047 [==============================] - 15s 941us/step - loss: 0.4706 - acc: 0.8756 - val_loss: 3.2384 - val_acc: 0.3273\n",
      "Epoch 78/100\n",
      "16047/16047 [==============================] - 15s 945us/step - loss: 0.4669 - acc: 0.8770 - val_loss: 3.3252 - val_acc: 0.3333\n",
      "Epoch 79/100\n",
      "16047/16047 [==============================] - 15s 938us/step - loss: 0.4461 - acc: 0.8838 - val_loss: 3.3662 - val_acc: 0.3323\n",
      "Epoch 80/100\n",
      "16047/16047 [==============================] - 15s 956us/step - loss: 0.4366 - acc: 0.8891 - val_loss: 3.3786 - val_acc: 0.3216\n",
      "Epoch 81/100\n",
      "16047/16047 [==============================] - 16s 974us/step - loss: 0.4316 - acc: 0.8877 - val_loss: 3.3673 - val_acc: 0.3301\n",
      "Epoch 82/100\n",
      "16047/16047 [==============================] - 15s 943us/step - loss: 0.4043 - acc: 0.8998 - val_loss: 3.4422 - val_acc: 0.3308\n",
      "Epoch 83/100\n",
      "16047/16047 [==============================] - 15s 945us/step - loss: 0.3906 - acc: 0.9048 - val_loss: 3.4169 - val_acc: 0.3259\n",
      "Epoch 84/100\n",
      "16047/16047 [==============================] - 16s 971us/step - loss: 0.3802 - acc: 0.9068 - val_loss: 3.4844 - val_acc: 0.3201\n",
      "Epoch 85/100\n",
      "16047/16047 [==============================] - 15s 939us/step - loss: 0.3782 - acc: 0.9080 - val_loss: 3.4943 - val_acc: 0.3313\n",
      "Epoch 86/100\n",
      "16047/16047 [==============================] - 15s 942us/step - loss: 0.3624 - acc: 0.9118 - val_loss: 3.5585 - val_acc: 0.3221\n",
      "Epoch 87/100\n",
      "16047/16047 [==============================] - 15s 943us/step - loss: 0.3500 - acc: 0.9161 - val_loss: 3.5511 - val_acc: 0.3191\n",
      "Epoch 88/100\n",
      "16047/16047 [==============================] - 15s 940us/step - loss: 0.3474 - acc: 0.9148 - val_loss: 3.6286 - val_acc: 0.3256\n",
      "Epoch 89/100\n",
      "16047/16047 [==============================] - 15s 938us/step - loss: 0.3337 - acc: 0.9219 - val_loss: 3.6584 - val_acc: 0.3256\n",
      "Epoch 90/100\n",
      "16047/16047 [==============================] - 15s 944us/step - loss: 0.3366 - acc: 0.9195 - val_loss: 3.6616 - val_acc: 0.3201\n",
      "Epoch 91/100\n",
      "16047/16047 [==============================] - 16s 969us/step - loss: 0.3137 - acc: 0.9275 - val_loss: 3.6593 - val_acc: 0.3186\n",
      "Epoch 92/100\n",
      "16047/16047 [==============================] - 15s 941us/step - loss: 0.2936 - acc: 0.9369 - val_loss: 3.7427 - val_acc: 0.3216\n",
      "Epoch 93/100\n",
      "16047/16047 [==============================] - 15s 938us/step - loss: 0.2813 - acc: 0.9396 - val_loss: 3.7695 - val_acc: 0.3184\n",
      "Epoch 94/100\n",
      "16047/16047 [==============================] - 15s 937us/step - loss: 0.2850 - acc: 0.9357 - val_loss: 3.7958 - val_acc: 0.3201\n",
      "Epoch 95/100\n",
      "16047/16047 [==============================] - 15s 959us/step - loss: 0.2820 - acc: 0.9345 - val_loss: 3.7959 - val_acc: 0.3089\n",
      "Epoch 96/100\n",
      "16047/16047 [==============================] - 15s 954us/step - loss: 0.2778 - acc: 0.9387 - val_loss: 3.8754 - val_acc: 0.3206\n",
      "Epoch 97/100\n",
      "16047/16047 [==============================] - 15s 937us/step - loss: 0.2601 - acc: 0.9444 - val_loss: 3.9390 - val_acc: 0.3091\n",
      "Epoch 98/100\n",
      "16047/16047 [==============================] - 15s 952us/step - loss: 0.2583 - acc: 0.9439 - val_loss: 3.8826 - val_acc: 0.3141\n",
      "Epoch 99/100\n",
      "16047/16047 [==============================] - 16s 972us/step - loss: 0.2632 - acc: 0.9404 - val_loss: 3.9291 - val_acc: 0.3179\n",
      "Epoch 100/100\n",
      "16047/16047 [==============================] - 16s 998us/step - loss: 0.2392 - acc: 0.9502 - val_loss: 3.9512 - val_acc: 0.3234\n"
     ]
    }
   ],
   "source": [
    "# RNN Model\n",
    "epochs = 100\n",
    "vocab_size = len(data_set)\n",
    "input_dim = vocab_size\n",
    "output_dim = vocab_size\n",
    "hidden_dim = 100\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(hidden_dim, input_shape=(None, vocab_size)))\n",
    "# rnn_model.add(SimpleRNN(hidden_dim, activation='tanh', return_sequences=True, input_shape=(None, vocab_size)))\n",
    "rnn_model.add(Dense(output_dim))\n",
    "rnn_model.add(Activation('softmax'))\n",
    "rnn_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "rnn_model.summary()\n",
    "print('Training')\n",
    "modelhistory = History()\n",
    "history = rnn_model.fit(xtr, ytr[:, -1, :], batch_size=128, nb_epoch=epochs, validation_data=(xva, yva[:, -1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with seed: \"<start>\n",
      "X:1\n",
      "T: La Montfar\"\n",
      "(900,)\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature):\n",
    "    # Helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# Function to get rnn layer output\n",
    "get_rnn_layer_output = K.function([rnn_model.layers[0].input], [rnn_model.layers[0].output])\n",
    "prime_len = 25\n",
    "gen_len = 900\n",
    "start_index = 0\n",
    "d = 0\n",
    "rnn_activations = []\n",
    "# T is Temperature parameter for Softmax layer.\n",
    "for T in [1.0]:\n",
    "    d += 1\n",
    "    generated = ''\n",
    "    sentence = data_str[start_index: start_index + prime_len]\n",
    "    generated += sentence\n",
    "    print('Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "    for i in range(gen_len):\n",
    "        x = np.zeros((1, prime_len, len(data_set)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_2_idx[char]] = 1.\n",
    "\n",
    "        preds = rnn_model.predict(x, verbose=0)[0]\n",
    "        layer_output = get_rnn_layer_output([x])[0]\n",
    "        rnn_activations.append(layer_output[0][-1])\n",
    "        next_index = sample(preds, T)\n",
    "        next_char = idx_2_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "    f = open('pred_feature' + '_' + str(T) + '_' + str(d) + '.txt', 'w')\n",
    "    f.write(generated)\n",
    "    f.close()\n",
    "    rnn_activations = np.array(rnn_activations)\n",
    "    print(rnn_activations.shape)\n",
    "    np.savetxt('rnn_activations_pred', rnn_activations, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "My trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "#import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models\n",
    "#importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'D:\\\\Resource\\\\Courses\\\\UCSD\\\\2nd_Quarter\\\\253\\\\pa4\\\\DeepMusic\\\\utils.py'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = utils.get_data()\n",
    "char2idx_dict, idx2char_dict = utils.get_dicts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = models.Music(voc_size=len(char2idx_dict), hidden_size=100, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach = utils.Trainer(lstm, char2idx_dict, idx2char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500, loss 1.717\n",
      "epoch 1000, loss 2.117\n",
      "epoch 1500, loss 1.836\n",
      "epoch 2000, loss 0.871\n",
      "epoch 2500, loss 1.566\n",
      "epoch 3000, loss 1.830\n"
     ]
    }
   ],
   "source": [
    "loss = coach.fit(data, max_iter=3000, log_freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaU88v8BnOEe9qfqRpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0828e6eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(loss))], loss)\n",
    "plt.xlabel('# of epochs')\n",
    "plt.ylabel('loss')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "\n",
      "X:49\n",
      "T:France the sonde observation mailto:galouvielle@free.fr\n",
      "M:4/4\n",
      "L:1/8\n",
      "K:D\n",
      "D>F GB|d2-|\n",
      "L:1/8\n",
      "K:D\n",
      "AB AB GB B2 :|\n",
      "|:G/A/ Bc d2B | A2 G2 | c2c d2 | d2 de | d2 e2 | e3 c/B/A/ | G2 G/E/ | FE F2 | F>GA\n"
     ]
    }
   ],
   "source": [
    "tune = \"<start>\\n\" + coach.inference(size=200, temp=.6)\n",
    "print(tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [c for c in '<start>']\n",
    "idx = coach.char2idx('<start>')\n",
    "hidden = lstm.init_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 40\n",
       " 60\n",
       " 82\n",
       " 14\n",
       "  8\n",
       " 82\n",
       " 67\n",
       "[torch.LongTensor of size 7]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20058.8"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
